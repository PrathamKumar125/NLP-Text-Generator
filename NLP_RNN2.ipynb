{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PrathamKumar125/NLP-Text-Generator/blob/master/NLP_RNN2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN Text Generator"
      ],
      "metadata": {
        "id": "DYkPAib_wksO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZe13EgowYVj",
        "outputId": "0b69ae91-313d-447b-8d98-b5f095eb2250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo7SRNqzXQZj",
        "outputId": "825613ca-920c-4ec6-ab43-574c9179486e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GR7Vv7TMsO3",
        "outputId": "72d6d125-0f09-4946-b973-9647d15067d6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m225.3/232.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "\n",
        "def pdf_to_text(pdf_file, txt_file):\n",
        "    text = ''\n",
        "    with open(pdf_file, 'rb') as f:\n",
        "        reader = PdfReader(f)\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text()\n",
        "\n",
        "    with open(txt_file, 'w', encoding='utf-8') as f:\n",
        "        f.write(text)\n",
        "\n",
        "# Provide the file paths\n",
        "pdf_file = \"/content/drive/MyDrive/NLP/Constitution.pdf\"\n",
        "txt_file = '/content/drive/MyDrive/NLP/Constitution.txt'\n",
        "\n",
        "# Convert PDF to text\n",
        "pdf_to_text(pdf_file, txt_file)\n"
      ],
      "metadata": {
        "id": "cSM2PcGfM6om"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file=\"/content/drive/MyDrive/NLP/Constitution.txt\""
      ],
      "metadata": {
        "id": "-MMwoD7fXJO2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=open(path_to_file,'rb').read().decode(encoding='utf-8')\n",
        "print(\"length of text: {} characters\".format(len(text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9O0FiKNylew",
        "outputId": "a6204f15-1ae5-465c-88d3-faf6c22f5fa5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of text: 876554 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:250])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_BKChPNzBnL",
        "outputId": "c2d77ae4-c9fd-41aa-b0a7-68a0abde43f3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " THE CONSTITUTION OF INDIA \n",
            "[As on       May , 2022] \n",
            "2022 \n",
            "  \n",
            " \n",
            "PREFACE \n",
            " \n",
            "This is the  fifth  pocket size edition of the Constitution of \n",
            "India in the diglot form. In this edition, the text of the \n",
            "Constitution of India has been brought u\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab=sorted(set(text))\n",
        "\n",
        "char2indx={u:i for i,u in enumerate(vocab)}\n",
        "indx2char=np.array(vocab)\n",
        "\n",
        "def text_to_int(text):\n",
        "  return np.array([char2indx[c] for c in text])\n",
        "\n",
        "text_as_int=text_to_int(text)"
      ],
      "metadata": {
        "id": "kxKH18y6zEyX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Text:\",text[:13])\n",
        "print(\"Encoded:\",text_to_int(text[:13]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RYmVYLw1EsN",
        "outputId": "68607b84-4ae7-4519-d3c7-ebc094574e70"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text:  \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " TH\n",
            "Encoded: [ 1  0  1  0  1  0  1  0  1  0  1 43 31]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def int_to_text(ints):\n",
        "  try:\n",
        "    ints=ints.numpy()\n",
        "  except:\n",
        "    pass\n",
        "  return ''.join(indx2char[ints])\n",
        "\n",
        "print(int_to_text(text_as_int[:13]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxhanfJI1Xvo",
        "outputId": "45bec7fe-8f78-45a3-e101-76cc6f93c9f0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " TH\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length=100\n",
        "examples_per_epoch=len(text)//(seq_length+1)\n",
        "char_dataset=tf.data.Dataset.from_tensor_slices(text_as_int)"
      ],
      "metadata": {
        "id": "_2ghQRA913cx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences=char_dataset.batch(seq_length+1,drop_remainder=True)"
      ],
      "metadata": {
        "id": "fBBlsWrP2jup"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(chunk):\n",
        "  input_text=chunk[:-1]\n",
        "  target_text=chunk[1:]\n",
        "  return input_text,target_text\n",
        "\n",
        "dataset=sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "9BF_qUti3ZKX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in dataset.take(2):\n",
        "  print(\"\\n\\nExample\\n\")\n",
        "  print(\"INPUT\")\n",
        "  print(int_to_text(x))\n",
        "  print(\"\\nOutput\")\n",
        "  print(int_to_text(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUr87-nq3ysD",
        "outputId": "eadebf65-d40f-4a24-b155-49f6e9e3e463"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Example\n",
            "\n",
            "INPUT\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " THE CONSTITUTION OF INDIA \n",
            "[As on       May , 2022] \n",
            "2022 \n",
            "  \n",
            " \n",
            "PREFACE \n",
            " \n",
            "This is the  f\n",
            "\n",
            "Output\n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " THE CONSTITUTION OF INDIA \n",
            "[As on       May , 2022] \n",
            "2022 \n",
            "  \n",
            " \n",
            "PREFACE \n",
            " \n",
            "This is the  fi\n",
            "\n",
            "\n",
            "Example\n",
            "\n",
            "INPUT\n",
            "fth  pocket size edition of the Constitution of \n",
            "India in the diglot form. In this edition, the text\n",
            "\n",
            "Output\n",
            "th  pocket size edition of the Constitution of \n",
            "India in the diglot form. In this edition, the text \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " BATCH_SIZE=128\n",
        " VOCAB_SIZE=len(vocab)\n",
        " EMBEDDING_DIM=256\n",
        " RNN_UNITS=1024\n",
        " BUFFER_SIZE=10000\n",
        " data=dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE,drop_remainder=True)"
      ],
      "metadata": {
        "id": "O6-ixED_4cd-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(vocab_size,embedding_dim,rnn_units,batch_size):\n",
        "  model=tf.keras.Sequential([\n",
        "      tf.keras.layers.Embedding(vocab_size,embedding_dim,batch_input_shape=[batch_size,None]),\n",
        "      tf.keras.layers.LSTM(rnn_units,return_sequences=True,\n",
        "                           stateful=True,\n",
        "                           recurrent_initializer=\"glorot_uniform\"),\n",
        "      tf.keras.layers.Dense(vocab_size)\n",
        "      ])\n",
        "  return model\n",
        "\n",
        "model=build_model(VOCAB_SIZE,EMBEDDING_DIM,RNN_UNITS,BATCH_SIZE)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dmyw7nAv6AP6",
        "outputId": "4eb2244d-f3b1-4302-9bc7-02daa98d6804"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (128, None, 256)          23040     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (128, None, 1024)         5246976   \n",
            "                                                                 \n",
            " dense (Dense)               (128, None, 90)           92250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5362266 (20.46 MB)\n",
            "Trainable params: 5362266 (20.46 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(labels,logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels,logits,from_logits=True)"
      ],
      "metadata": {
        "id": "40_qsH0zYCvs"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\",loss=loss)"
      ],
      "metadata": {
        "id": "-opTt67GivHV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint( filepath=checkpoint_prefix, save_weights_only=True)"
      ],
      "metadata": {
        "id": "wV82B_kJi3I3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(data,epochs=100,callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSuXFvW7jHUl",
        "outputId": "5d645ee9-b498-46c3-b26e-fa46f9f14768"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "67/67 [==============================] - 14s 144ms/step - loss: 3.1631\n",
            "Epoch 2/100\n",
            "67/67 [==============================] - 11s 125ms/step - loss: 2.2844\n",
            "Epoch 3/100\n",
            "67/67 [==============================] - 10s 127ms/step - loss: 1.7966\n",
            "Epoch 4/100\n",
            "67/67 [==============================] - 10s 126ms/step - loss: 1.4689\n",
            "Epoch 5/100\n",
            "67/67 [==============================] - 10s 129ms/step - loss: 1.2630\n",
            "Epoch 6/100\n",
            "67/67 [==============================] - 10s 131ms/step - loss: 1.1318\n",
            "Epoch 7/100\n",
            "67/67 [==============================] - 10s 135ms/step - loss: 1.0379\n",
            "Epoch 8/100\n",
            "67/67 [==============================] - 11s 137ms/step - loss: 0.9698\n",
            "Epoch 9/100\n",
            "67/67 [==============================] - 11s 140ms/step - loss: 0.9141\n",
            "Epoch 10/100\n",
            "67/67 [==============================] - 11s 143ms/step - loss: 0.8687\n",
            "Epoch 11/100\n",
            "67/67 [==============================] - 11s 148ms/step - loss: 0.8304\n",
            "Epoch 12/100\n",
            "67/67 [==============================] - 11s 144ms/step - loss: 0.7957\n",
            "Epoch 13/100\n",
            "67/67 [==============================] - 12s 146ms/step - loss: 0.7647\n",
            "Epoch 14/100\n",
            "67/67 [==============================] - 12s 146ms/step - loss: 0.7363\n",
            "Epoch 15/100\n",
            "67/67 [==============================] - 12s 144ms/step - loss: 0.7066\n",
            "Epoch 16/100\n",
            "67/67 [==============================] - 11s 142ms/step - loss: 0.6823\n",
            "Epoch 17/100\n",
            "67/67 [==============================] - 11s 144ms/step - loss: 0.6577\n",
            "Epoch 18/100\n",
            "67/67 [==============================] - 12s 151ms/step - loss: 0.6339\n",
            "Epoch 19/100\n",
            "67/67 [==============================] - 13s 149ms/step - loss: 0.6112\n",
            "Epoch 20/100\n",
            "67/67 [==============================] - 12s 146ms/step - loss: 0.5897\n",
            "Epoch 21/100\n",
            "67/67 [==============================] - 11s 144ms/step - loss: 0.5680\n",
            "Epoch 22/100\n",
            "67/67 [==============================] - 11s 143ms/step - loss: 0.5481\n",
            "Epoch 23/100\n",
            "67/67 [==============================] - 11s 150ms/step - loss: 0.5303\n",
            "Epoch 24/100\n",
            "67/67 [==============================] - 11s 145ms/step - loss: 0.5120\n",
            "Epoch 25/100\n",
            "67/67 [==============================] - 11s 146ms/step - loss: 0.4954\n",
            "Epoch 26/100\n",
            "67/67 [==============================] - 11s 146ms/step - loss: 0.4793\n",
            "Epoch 27/100\n",
            "67/67 [==============================] - 11s 142ms/step - loss: 0.4650\n",
            "Epoch 28/100\n",
            "67/67 [==============================] - 11s 144ms/step - loss: 0.4501\n",
            "Epoch 29/100\n",
            "67/67 [==============================] - 11s 150ms/step - loss: 0.4368\n",
            "Epoch 30/100\n",
            "67/67 [==============================] - 11s 151ms/step - loss: 0.4226\n",
            "Epoch 31/100\n",
            "67/67 [==============================] - 12s 146ms/step - loss: 0.4107\n",
            "Epoch 32/100\n",
            "67/67 [==============================] - 11s 144ms/step - loss: 0.3998\n",
            "Epoch 33/100\n",
            "67/67 [==============================] - 11s 142ms/step - loss: 0.3901\n",
            "Epoch 34/100\n",
            "67/67 [==============================] - 12s 144ms/step - loss: 0.3794\n",
            "Epoch 35/100\n",
            "67/67 [==============================] - 13s 148ms/step - loss: 0.3713\n",
            "Epoch 36/100\n",
            "67/67 [==============================] - 12s 146ms/step - loss: 0.3621\n",
            "Epoch 37/100\n",
            "67/67 [==============================] - 12s 145ms/step - loss: 0.3530\n",
            "Epoch 38/100\n",
            "67/67 [==============================] - 11s 144ms/step - loss: 0.3464\n",
            "Epoch 39/100\n",
            "67/67 [==============================] - 11s 143ms/step - loss: 0.3391\n",
            "Epoch 40/100\n",
            "67/67 [==============================] - 11s 143ms/step - loss: 0.3312\n",
            "Epoch 41/100\n",
            "67/67 [==============================] - 11s 143ms/step - loss: 0.3250\n",
            "Epoch 42/100\n",
            "67/67 [==============================] - 11s 145ms/step - loss: 0.3203\n",
            "Epoch 43/100\n",
            "67/67 [==============================] - 12s 145ms/step - loss: 0.3136\n",
            "Epoch 44/100\n",
            "67/67 [==============================] - 11s 142ms/step - loss: 0.3073\n",
            "Epoch 45/100\n",
            "67/67 [==============================] - 11s 146ms/step - loss: 0.3025\n",
            "Epoch 46/100\n",
            "67/67 [==============================] - 11s 145ms/step - loss: 0.2986\n",
            "Epoch 47/100\n",
            "67/67 [==============================] - 12s 145ms/step - loss: 0.2955\n",
            "Epoch 48/100\n",
            "67/67 [==============================] - 11s 148ms/step - loss: 0.2901\n",
            "Epoch 49/100\n",
            "67/67 [==============================] - 11s 148ms/step - loss: 0.2860\n",
            "Epoch 50/100\n",
            "67/67 [==============================] - 11s 145ms/step - loss: 0.2833\n",
            "Epoch 51/100\n",
            "67/67 [==============================] - 11s 143ms/step - loss: 0.2791\n",
            "Epoch 52/100\n",
            "67/67 [==============================] - 11s 140ms/step - loss: 0.2749\n",
            "Epoch 53/100\n",
            "67/67 [==============================] - 12s 145ms/step - loss: 0.2716\n",
            "Epoch 54/100\n",
            "67/67 [==============================] - 12s 149ms/step - loss: 0.2703\n",
            "Epoch 55/100\n",
            "67/67 [==============================] - 12s 147ms/step - loss: 0.2675\n",
            "Epoch 56/100\n",
            "67/67 [==============================] - 11s 147ms/step - loss: 0.2647\n",
            "Epoch 57/100\n",
            "67/67 [==============================] - 11s 144ms/step - loss: 0.2611\n",
            "Epoch 58/100\n",
            "67/67 [==============================] - 11s 144ms/step - loss: 0.2600\n",
            "Epoch 59/100\n",
            "67/67 [==============================] - 11s 141ms/step - loss: 0.2557\n",
            "Epoch 60/100\n",
            "67/67 [==============================] - 12s 144ms/step - loss: 0.2554\n",
            "Epoch 61/100\n",
            "67/67 [==============================] - 11s 146ms/step - loss: 0.2506\n",
            "Epoch 62/100\n",
            "67/67 [==============================] - 11s 149ms/step - loss: 0.2500\n",
            "Epoch 63/100\n",
            "67/67 [==============================] - 11s 147ms/step - loss: 0.2482\n",
            "Epoch 64/100\n",
            "67/67 [==============================] - 11s 142ms/step - loss: 0.2456\n",
            "Epoch 65/100\n",
            "67/67 [==============================] - 12s 144ms/step - loss: 0.2445\n",
            "Epoch 66/100\n",
            "67/67 [==============================] - 12s 146ms/step - loss: 0.2423\n",
            "Epoch 67/100\n",
            "67/67 [==============================] - 11s 147ms/step - loss: 0.2408\n",
            "Epoch 68/100\n",
            "67/67 [==============================] - 11s 142ms/step - loss: 0.2404\n",
            "Epoch 69/100\n",
            "67/67 [==============================] - 11s 145ms/step - loss: 0.2372\n",
            "Epoch 70/100\n",
            "67/67 [==============================] - 11s 147ms/step - loss: 0.2355\n",
            "Epoch 71/100\n",
            "67/67 [==============================] - 11s 143ms/step - loss: 0.2341\n",
            "Epoch 72/100\n",
            "67/67 [==============================] - 11s 144ms/step - loss: 0.2340\n",
            "Epoch 73/100\n",
            "67/67 [==============================] - 11s 149ms/step - loss: 0.2317\n",
            "Epoch 74/100\n",
            "67/67 [==============================] - 11s 150ms/step - loss: 0.2297\n",
            "Epoch 75/100\n",
            "67/67 [==============================] - 11s 146ms/step - loss: 0.2288\n",
            "Epoch 76/100\n",
            "67/67 [==============================] - 12s 144ms/step - loss: 0.2271\n",
            "Epoch 77/100\n",
            "67/67 [==============================] - 12s 143ms/step - loss: 0.2256\n",
            "Epoch 78/100\n",
            "67/67 [==============================] - 11s 141ms/step - loss: 0.2261\n",
            "Epoch 79/100\n",
            "67/67 [==============================] - 11s 145ms/step - loss: 0.2241\n",
            "Epoch 80/100\n",
            "67/67 [==============================] - 11s 147ms/step - loss: 0.2230\n",
            "Epoch 81/100\n",
            "67/67 [==============================] - 12s 150ms/step - loss: 0.2221\n",
            "Epoch 82/100\n",
            "67/67 [==============================] - 11s 144ms/step - loss: 0.2206\n",
            "Epoch 83/100\n",
            "67/67 [==============================] - 11s 145ms/step - loss: 0.2198\n",
            "Epoch 84/100\n",
            "67/67 [==============================] - 11s 145ms/step - loss: 0.2183\n",
            "Epoch 85/100\n",
            "67/67 [==============================] - 11s 145ms/step - loss: 0.2176\n",
            "Epoch 86/100\n",
            "67/67 [==============================] - 11s 145ms/step - loss: 0.2163\n",
            "Epoch 87/100\n",
            "67/67 [==============================] - 12s 144ms/step - loss: 0.2169\n",
            "Epoch 88/100\n",
            "67/67 [==============================] - 12s 143ms/step - loss: 0.2164\n",
            "Epoch 89/100\n",
            "67/67 [==============================] - 11s 144ms/step - loss: 0.2142\n",
            "Epoch 90/100\n",
            "67/67 [==============================] - 11s 144ms/step - loss: 0.2138\n",
            "Epoch 91/100\n",
            "67/67 [==============================] - 11s 145ms/step - loss: 0.2121\n",
            "Epoch 92/100\n",
            "67/67 [==============================] - 11s 145ms/step - loss: 0.2109\n",
            "Epoch 93/100\n",
            "67/67 [==============================] - 11s 145ms/step - loss: 0.2113\n",
            "Epoch 94/100\n",
            "67/67 [==============================] - 12s 141ms/step - loss: 0.2092\n",
            "Epoch 95/100\n",
            "67/67 [==============================] - 12s 145ms/step - loss: 0.2104\n",
            "Epoch 96/100\n",
            "67/67 [==============================] - 11s 150ms/step - loss: 0.2093\n",
            "Epoch 97/100\n",
            "67/67 [==============================] - 11s 147ms/step - loss: 0.2069\n",
            "Epoch 98/100\n",
            "67/67 [==============================] - 11s 145ms/step - loss: 0.2055\n",
            "Epoch 99/100\n",
            "67/67 [==============================] - 11s 141ms/step - loss: 0.2052\n",
            "Epoch 100/100\n",
            "67/67 [==============================] - 12s 144ms/step - loss: 0.2048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=build_model(VOCAB_SIZE,EMBEDDING_DIM,RNN_UNITS,batch_size=1)"
      ],
      "metadata": {
        "id": "AlNmqITujZy4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1,None]))"
      ],
      "metadata": {
        "id": "DXvJr-Y0zLvB"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model,start_string):\n",
        "  num_generate=500\n",
        "  input_eval=[char2indx[s] for s in start_string]\n",
        "  input_eval=tf.expand_dims(input_eval,0)\n",
        "\n",
        "  text_generated=[]\n",
        "\n",
        "  temperature=1.0\n",
        "  model.reset_states()\n",
        "\n",
        "  for i in range(num_generate):\n",
        "    predictions=model(input_eval)\n",
        "\n",
        "    predictions=tf.squeeze(predictions,0)\n",
        "    predictions=predictions/temperature\n",
        "    predicted_id=tf.random.categorical(predictions,num_samples=1)[-1,0].numpy()\n",
        "\n",
        "    input_eval=tf.expand_dims([predicted_id],0)\n",
        "\n",
        "    text_generated.append(indx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))\n"
      ],
      "metadata": {
        "id": "bLtJdXeNNRYp"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_txt=input(\"Type starting string:\\n\")\n",
        "print(generate_text(model,input_txt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcUWnRohQwpD",
        "outputId": "6678ad09-f779-4c0c-c841-10edba5e84f0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type starting string:\n",
            "Constitution of India\n",
            "Constitution of India as by \n",
            "law established, 1[that I will uphold the sovereignty and inthirgures havendation of the autonomous State unless the Governor in the interests of \n",
            "the said twenty-\n",
            "sixthenty Assembly, \n",
            "suct paragraph, and by \n",
            "reason the working of members of the Legislative Council of \n",
            "a State shall have the rissolvement and Deulthe \n",
            "Government of any State or under any other law for the time being in force. \n",
            "73. The Vice-President  to be elected under sub-clauses ( a), (b) and (c) of \n",
            "clause (3) of arti\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1b7oWa2NQ_q4"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}